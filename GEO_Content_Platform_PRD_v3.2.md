# Multi-Agent GEO Content Optimization Platform

## Product Requirements Document v3.2

**Document Version:** 3.2  
**Date:** December 1, 2025  
**Prepared By:** Tocanan.ai  
**Status:** Final Draft  

---

## 1. Executive Summary

This document specifies a multi-agent content optimization platform designed to maximize client visibility in generative search engines (ChatGPT, Perplexity AI, Google AI Overviews, Claude). The platform employs an agentic AI architecture built on the **OpenAI Agent SDK** framework, with specialized agents for autonomous research, parallel content generation (OpenAI GPT-4.1-mini + Claude 3.5 Haiku), and quality evaluation with iterative refinement.

### 1.1 Technology Stack Overview

| Component | Technology | Rationale |
|-----------|------------|-----------|
| **Agent Framework** | OpenAI Agent SDK | Native agent orchestration with tool calling, handoffs, and guardrails |
| **Agent Tracing** | OpenAI Trace | End-to-end observability of agent workflows |
| **Writer Agent A** | GPT-4.1-mini | Cost-effective, fast generation with strong instruction-following |
| **Writer Agent B** | Claude 3.5 Haiku | Equivalent tier from Anthropic; natural fluency and speed |
| **Evaluator Agent** | GPT-4.1 or Claude 3.5 Sonnet | Higher capability for nuanced evaluation |
| **Web Harvesting** | Pathway | Real-time data pipeline for web content extraction |
| **Environment** | uv | Fast Python package management and virtual environments |

### 1.2 Key Features

| Feature | Description |
|---------|-------------|
| **Automatic Language Detection** | Output article matches input question language (English, Traditional Chinese, Simplified Chinese, Arabic dialects) |
| **Full Observability** | OpenAI Trace integration for complete agent workflow tracking |
| **GEO Performance Commentary** | Evaluator provides detailed explanation of why selected output excels |
| **Dual-LLM Generation** | Parallel content creation for best-of-breed output |
| **Research-Backed Optimization** | Evidence-based GEO strategies with 30-40% visibility improvement |

### 1.3 Research Foundation

The platform's optimization framework is grounded in peer-reviewed academic research:

| Study | Key Finding | Application |
|-------|-------------|-------------|
| Aggarwal et al. (2024) KDD '24 | GEO strategies boost visibility up to 40% | Core optimization strategies |
| Aggarwal et al. (2024) | Combined strategies (Fluency + Statistics) yield 35.8% improvement | Multi-strategy application |
| Luttgenau et al. (2025) arXiv | Domain-specific fine-tuning achieves 30.96% position-adjusted visibility gain | Industry-specific optimization |

---

## 2. Language Detection & Multilingual Support

### 2.1 Supported Languages

The platform automatically detects the language of the input question and generates content in the same language:

| Language | Code | Variants/Dialects |
|----------|------|-------------------|
| **English** | `en` | US, UK, Australian |
| **Traditional Chinese** | `zh-TW` | Taiwan, Hong Kong |
| **Simplified Chinese** | `zh-CN` | Mainland China, Singapore |
| **Arabic - Modern Standard** | `ar-MSA` | Formal/written Arabic |
| **Arabic - Gulf** | `ar-Gulf` | UAE, Saudi Arabia, Kuwait, Qatar, Bahrain, Oman |
| **Arabic - Egyptian** | `ar-EG` | Egypt |
| **Arabic - Levantine** | `ar-Levant` | Lebanon, Syria, Jordan, Palestine |
| **Arabic - Maghrebi** | `ar-Maghreb` | Morocco, Algeria, Tunisia, Libya |

### 2.2 Language Detection Implementation

```python
from openai_agents import Tool
from pydantic import BaseModel
from typing import Literal

class LanguageDetectionResult(BaseModel):
    """Result of language detection."""
    detected_language: str
    language_code: str
    confidence: float
    dialect: str | None = None
    writing_direction: Literal["ltr", "rtl"]

class LanguageDetectorTool(Tool):
    """Detect language and dialect of input text."""
    
    name = "detect_language"
    description = "Detect the language and dialect of the input question"
    
    parameters = {
        "type": "object",
        "properties": {
            "text": {
                "type": "string",
                "description": "The text to analyze for language detection"
            }
        },
        "required": ["text"]
    }
    
    # Language detection patterns and markers
    ARABIC_DIALECT_MARKERS = {
        "ar-Gulf": ["Ø´Ù„ÙˆÙ†Ùƒ", "ÙˆØ§ÙŠØ¯", "Ø²ÙŠÙ†", "Ù‡Ø§Ù„Ø­ÙŠÙ†", "Ø¥Ù…Ø¨Ù‰"],
        "ar-EG": ["Ø¥Ø²ÙŠÙƒ", "ÙƒØ¯Ù‡", "Ø¨Ø±Ø¶Ùˆ", "Ø¹Ø§ÙŠØ²", "ÙÙŠÙ†"],
        "ar-Levant": ["ÙƒÙŠÙÙƒ", "Ù‡Ù„Ù‚", "Ø´Ùˆ", "Ù…Ù†ÙŠØ­", "Ù‡ÙŠÙƒ"],
        "ar-Maghreb": ["ÙˆØ§Ø´", "Ø¨Ø²Ø§Ù", "ÙƒÙŠÙØ§Ø´", "Ø¯ÙŠØ§Ù„", "ØºØ§Ø¯ÙŠ"],
    }
    
    CHINESE_MARKERS = {
        "zh-TW": ["è‡ºç£", "è»Ÿé«”", "ç¶²éš›ç¶²è·¯", "è³‡è¨Š", "è¨˜æ†¶é«”"],  # Traditional
        "zh-CN": ["å°æ¹¾", "è½¯ä»¶", "äº’è”ç½‘", "ä¿¡æ¯", "å†…å­˜"],      # Simplified
    }
    
    async def execute(self, text: str) -> LanguageDetectionResult:
        """Detect language with dialect identification."""
        import re
        
        # Check for Arabic script
        if re.search(r'[\u0600-\u06FF]', text):
            dialect = self._detect_arabic_dialect(text)
            return LanguageDetectionResult(
                detected_language="Arabic",
                language_code=dialect,
                confidence=0.95,
                dialect=dialect.split("-")[1] if "-" in dialect else "MSA",
                writing_direction="rtl"
            )
        
        # Check for Chinese characters
        if re.search(r'[\u4e00-\u9fff]', text):
            variant = self._detect_chinese_variant(text)
            return LanguageDetectionResult(
                detected_language="Chinese",
                language_code=variant,
                confidence=0.95,
                dialect="Traditional" if variant == "zh-TW" else "Simplified",
                writing_direction="ltr"
            )
        
        # Default to English
        return LanguageDetectionResult(
            detected_language="English",
            language_code="en",
            confidence=0.90,
            dialect=None,
            writing_direction="ltr"
        )
    
    def _detect_arabic_dialect(self, text: str) -> str:
        """Identify Arabic dialect from text markers."""
        text_lower = text.lower()
        
        for dialect, markers in self.ARABIC_DIALECT_MARKERS.items():
            if any(marker in text for marker in markers):
                return dialect
        
        # Default to Modern Standard Arabic
        return "ar-MSA"
    
    def _detect_chinese_variant(self, text: str) -> str:
        """Identify Traditional vs Simplified Chinese."""
        # Check for Traditional Chinese specific characters
        traditional_chars = set("è‡ºè»Ÿç¶²éš›è³‡è¨Šè¨˜æ†¶é«”è™•è£¡æ©Ÿå­¸ç¿’æ•¸æ“šè¦–é »ç¶²çµ¡")
        simplified_chars = set("å°è½¯ç½‘é™…èµ„è®¯è®°å¿†ä½“å¤„é‡Œæœºå­¦ä¹ æ•°æ®è§†é¢‘ç½‘ç»œ")
        
        trad_count = sum(1 for c in text if c in traditional_chars)
        simp_count = sum(1 for c in text if c in simplified_chars)
        
        return "zh-TW" if trad_count >= simp_count else "zh-CN"

language_detector = LanguageDetectorTool()
```

### 2.3 Multilingual Content Generation

```python
# Language-specific system prompt additions
LANGUAGE_PROMPTS = {
    "en": """
Write in fluent, natural English. Use American English spelling conventions
unless the context suggests British English is more appropriate.
""",
    
    "zh-TW": """
ä½¿ç”¨ç¹é«”ä¸­æ–‡æ’°å¯«å…§å®¹ã€‚æ¡ç”¨å°ç£åœ°å€å¸¸ç”¨çš„è©å½™å’Œè¡¨é”æ–¹å¼ã€‚
ä¾‹å¦‚ï¼šä½¿ç”¨ã€Œè»Ÿé«”ã€è€Œéã€Œè½¯ä»¶ã€ï¼Œã€Œç¶²éš›ç¶²è·¯ã€è€Œéã€Œäº’è”ç½‘ã€ã€‚
ç¢ºä¿æ–‡ç« æµæš¢è‡ªç„¶ï¼Œç¬¦åˆç¹é«”ä¸­æ–‡é–±è®€ç¿’æ…£ã€‚
""",
    
    "zh-CN": """
ä½¿ç”¨ç®€ä½“ä¸­æ–‡æ’°å†™å†…å®¹ã€‚é‡‡ç”¨ä¸­å›½å¤§é™†åœ°åŒºå¸¸ç”¨çš„è¯æ±‡å’Œè¡¨è¾¾æ–¹å¼ã€‚
ä¾‹å¦‚ï¼šä½¿ç”¨ã€Œè½¯ä»¶ã€è€Œéã€Œè»Ÿé«”ã€ï¼Œã€Œäº’è”ç½‘ã€è€Œéã€Œç¶²éš›ç¶²è·¯ã€ã€‚
ç¡®ä¿æ–‡ç« æµç•…è‡ªç„¶ï¼Œç¬¦åˆç®€ä½“ä¸­æ–‡é˜…è¯»ä¹ æƒ¯ã€‚
""",
    
    "ar-MSA": """
Ø§ÙƒØªØ¨ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„ÙØµØ­Ù‰ Ø§Ù„Ø­Ø¯ÙŠØ«Ø©. Ø§Ø³ØªØ®Ø¯Ù… Ø£Ø³Ù„ÙˆØ¨Ø§Ù‹ Ø±Ø³Ù…ÙŠØ§Ù‹ ÙˆÙ…Ù‡Ù†ÙŠØ§Ù‹.
ØªØ£ÙƒØ¯ Ù…Ù† ØµØ­Ø© Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ù†Ø­ÙˆÙŠØ© ÙˆØ§Ù„Ø¥Ù…Ù„Ø§Ø¦ÙŠØ©.
Ø§Ø¬Ø¹Ù„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ ÙˆØ§Ø¶Ø­Ø§Ù‹ ÙˆØ³Ù‡Ù„ Ø§Ù„Ù‚Ø±Ø§Ø¡Ø©.
""",
    
    "ar-Gulf": """
Ø§ÙƒØªØ¨ Ø¨Ø§Ù„Ù„Ù‡Ø¬Ø© Ø§Ù„Ø®Ù„ÙŠØ¬ÙŠØ© Ù…Ø¹ Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù‡Ù†ÙŠØ©.
Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù…ØµØ·Ù„Ø­Ø§Øª ÙˆØ§Ù„ØªØ¹Ø¨ÙŠØ±Ø§Øª Ø§Ù„Ø´Ø§Ø¦Ø¹Ø© ÙÙŠ Ø¯ÙˆÙ„ Ø§Ù„Ø®Ù„ÙŠØ¬ Ø§Ù„Ø¹Ø±Ø¨ÙŠ.
Ø§Ø¬Ø¹Ù„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ù…Ù†Ø§Ø³Ø¨Ø§Ù‹ Ù„Ù„Ø¬Ù…Ù‡ÙˆØ± ÙÙŠ Ø§Ù„Ø¥Ù…Ø§Ø±Ø§Øª ÙˆØ§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ© ÙˆØ§Ù„ÙƒÙˆÙŠØª ÙˆÙ‚Ø·Ø± ÙˆØ§Ù„Ø¨Ø­Ø±ÙŠÙ† ÙˆØ¹Ù…Ø§Ù†.
""",
    
    "ar-EG": """
Ø§ÙƒØªØ¨ Ø¨Ø§Ù„Ù„Ù‡Ø¬Ø© Ø§Ù„Ù…ØµØ±ÙŠØ© Ù…Ø¹ Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù‡Ù†ÙŠØ©.
Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù…ØµØ·Ù„Ø­Ø§Øª ÙˆØ§Ù„ØªØ¹Ø¨ÙŠØ±Ø§Øª Ø§Ù„Ø´Ø§Ø¦Ø¹Ø© ÙÙŠ Ù…ØµØ±.
Ø§Ø¬Ø¹Ù„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ ÙˆØ§Ø¶Ø­Ø§Ù‹ ÙˆÙ…ÙÙ‡ÙˆÙ…Ø§Ù‹ Ù„Ù„Ø¬Ù…Ù‡ÙˆØ± Ø§Ù„Ù…ØµØ±ÙŠ.
""",
    
    "ar-Levant": """
Ø§ÙƒØªØ¨ Ø¨Ø§Ù„Ù„Ù‡Ø¬Ø© Ø§Ù„Ø´Ø§Ù…ÙŠØ© Ù…Ø¹ Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù‡Ù†ÙŠØ©.
Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù…ØµØ·Ù„Ø­Ø§Øª ÙˆØ§Ù„ØªØ¹Ø¨ÙŠØ±Ø§Øª Ø§Ù„Ø´Ø§Ø¦Ø¹Ø© ÙÙŠ Ù„Ø¨Ù†Ø§Ù† ÙˆØ³ÙˆØ±ÙŠØ§ ÙˆØ§Ù„Ø£Ø±Ø¯Ù† ÙˆÙÙ„Ø³Ø·ÙŠÙ†.
Ø§Ø¬Ø¹Ù„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ù…Ù†Ø§Ø³Ø¨Ø§Ù‹ Ù„Ø¬Ù…Ù‡ÙˆØ± Ø¨Ù„Ø§Ø¯ Ø§Ù„Ø´Ø§Ù….
""",
    
    "ar-Maghreb": """
Ø§ÙƒØªØ¨ Ø¨Ø§Ù„Ù„Ù‡Ø¬Ø© Ø§Ù„Ù…ØºØ§Ø±Ø¨ÙŠØ© Ù…Ø¹ Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù‡Ù†ÙŠØ©.
Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù…ØµØ·Ù„Ø­Ø§Øª ÙˆØ§Ù„ØªØ¹Ø¨ÙŠØ±Ø§Øª Ø§Ù„Ø´Ø§Ø¦Ø¹Ø© ÙÙŠ Ø§Ù„Ù…ØºØ±Ø¨ ÙˆØ§Ù„Ø¬Ø²Ø§Ø¦Ø± ÙˆØªÙˆÙ†Ø³ ÙˆÙ„ÙŠØ¨ÙŠØ§.
Ø§Ø¬Ø¹Ù„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ù…ÙÙ‡ÙˆÙ…Ø§Ù‹ Ù„Ø¬Ù…Ù‡ÙˆØ± Ø´Ù…Ø§Ù„ Ø£ÙØ±ÙŠÙ‚ÙŠØ§.
""",
}

def get_localized_system_prompt(base_prompt: str, language_code: str) -> str:
    """Combine base GEO prompt with language-specific instructions."""
    language_instruction = LANGUAGE_PROMPTS.get(language_code, LANGUAGE_PROMPTS["en"])
    
    return f"""{base_prompt}

### LANGUAGE REQUIREMENTS
{language_instruction}

CRITICAL: The entire output MUST be written in the same language as the input question.
Do not mix languages. Maintain consistent language throughout the article.
"""
```

### 2.4 RTL (Right-to-Left) Support for Arabic

```python
class RTLContentFormatter(Tool):
    """Format content for RTL languages."""
    
    name = "format_rtl_content"
    description = "Format content for right-to-left languages like Arabic"
    
    async def execute(self, content: str, language_code: str) -> dict:
        """Add RTL formatting and validate Arabic content."""
        
        if not language_code.startswith("ar-"):
            return {"content": content, "rtl": False}
        
        # Add RTL markers and validate
        formatted_content = self._add_rtl_formatting(content)
        
        return {
            "content": formatted_content,
            "rtl": True,
            "direction": "rtl",
            "html_wrapper": f'<div dir="rtl" lang="{language_code}">{formatted_content}</div>'
        }
    
    def _add_rtl_formatting(self, content: str) -> str:
        """Ensure proper RTL formatting."""
        # Add RTL mark at start of paragraphs
        import re
        paragraphs = content.split('\n\n')
        formatted = []
        for p in paragraphs:
            if p.strip():
                formatted.append('\u200F' + p)  # Add RTL mark
        return '\n\n'.join(formatted)
```

---

## 3. OpenAI Trace Integration

### 3.1 Tracing Overview

The platform uses **OpenAI Trace** for complete observability of agent workflows, enabling:
- End-to-end tracking of content generation
- Performance monitoring and debugging
- Cost analysis per generation request
- Quality assurance through workflow inspection

### 3.2 Trace Configuration

```python
from openai_agents import Agent, trace
from openai_agents.tracing import TracingConfig, TraceExporter
import os

# Configure tracing
tracing_config = TracingConfig(
    enabled=True,
    service_name="geo-content-platform",
    environment=os.getenv("ENVIRONMENT", "development"),
    
    # Export to OpenAI dashboard
    exporter=TraceExporter.OPENAI_DASHBOARD,
    
    # Additional exporters (optional)
    additional_exporters=[
        TraceExporter.CONSOLE,  # Local debugging
        # TraceExporter.CUSTOM,  # Custom exporter for internal systems
    ],
    
    # Trace detail level
    capture_inputs=True,
    capture_outputs=True,
    capture_tool_calls=True,
    capture_handoffs=True,
    
    # Metadata to include in all traces
    default_metadata={
        "platform": "geo-content-platform",
        "version": "3.2.0",
    }
)

# Initialize tracing globally
trace.configure(tracing_config)
```

### 3.3 Traced Agent Workflow

```python
from openai_agents import Agent, Runner, trace
from openai_agents.tracing import Span, SpanKind
import uuid

class GEOContentWorkflow:
    """Main workflow orchestrator with full tracing."""
    
    def __init__(self):
        self.research_agent = research_agent
        self.writer_agent_a = writer_agent_a
        self.writer_agent_b = writer_agent_b
        self.evaluator_agent = evaluator_agent
        self.language_detector = language_detector
    
    @trace.workflow(name="geo_content_generation")
    async def generate_content(
        self,
        client_name: str,
        target_question: str,
        reference_urls: list[str] = None,
        reference_documents: list[str] = None,
    ) -> dict:
        """
        Execute full content generation workflow with tracing.
        
        Each step is traced for observability in OpenAI dashboard.
        """
        
        # Generate unique trace ID for this request
        trace_id = str(uuid.uuid4())
        
        # Add trace metadata
        trace.set_metadata({
            "trace_id": trace_id,
            "client_name": client_name,
            "request_timestamp": datetime.utcnow().isoformat(),
        })
        
        # Step 1: Language Detection
        with trace.span("language_detection", kind=SpanKind.INTERNAL) as span:
            language_result = await self.language_detector.execute(target_question)
            span.set_attribute("detected_language", language_result.language_code)
            span.set_attribute("confidence", language_result.confidence)
        
        # Step 2: Research Phase
        with trace.span("research_phase", kind=SpanKind.AGENT) as span:
            span.set_attribute("agent", "ResearchAgent")
            research_brief = await self._run_research(
                client_name, 
                target_question,
                reference_urls,
                reference_documents
            )
            span.set_attribute("sources_found", len(research_brief.get("sources", [])))
            span.set_attribute("statistics_found", len(research_brief.get("statistics", [])))
        
        # Step 3: Parallel Content Generation
        with trace.span("content_generation", kind=SpanKind.AGENT) as span:
            draft_a, draft_b = await self._generate_drafts_parallel(
                research_brief,
                target_question,
                language_result.language_code
            )
            span.set_attribute("draft_a_word_count", len(draft_a.split()))
            span.set_attribute("draft_b_word_count", len(draft_b.split()))
        
        # Step 4: Evaluation Loop
        with trace.span("evaluation_loop", kind=SpanKind.AGENT) as span:
            final_result = await self._evaluation_loop(
                draft_a,
                draft_b,
                research_brief,
                target_question,
                language_result.language_code
            )
            span.set_attribute("iterations", final_result["iterations"])
            span.set_attribute("selected_draft", final_result["selected"])
            span.set_attribute("final_score", final_result["score"])
        
        # Add final trace summary
        trace.set_metadata({
            "completion_status": "success",
            "total_duration_ms": trace.current_span().duration_ms,
            "selected_draft": final_result["selected"],
            "final_score": final_result["score"],
        })
        
        return {
            "trace_id": trace_id,
            "content": final_result["content"],
            "language": language_result.language_code,
            "evaluation": final_result["evaluation"],
            "geo_commentary": final_result["geo_commentary"],
            "trace_url": f"https://platform.openai.com/traces/{trace_id}"
        }
    
    @trace.span("research_execution")
    async def _run_research(
        self,
        client_name: str,
        target_question: str,
        reference_urls: list[str],
        reference_documents: list[str]
    ) -> dict:
        """Execute research agent with tracing."""
        
        runner = Runner(agent=self.research_agent)
        result = await runner.run(
            input={
                "client_name": client_name,
                "target_question": target_question,
                "reference_urls": reference_urls or [],
                "reference_documents": reference_documents or [],
            }
        )
        return result.output
    
    @trace.span("parallel_draft_generation")
    async def _generate_drafts_parallel(
        self,
        research_brief: dict,
        target_question: str,
        language_code: str
    ) -> tuple[str, str]:
        """Generate drafts from both writers in parallel with tracing."""
        import asyncio
        
        # Prepare localized prompts
        localized_prompt_a = get_localized_system_prompt(
            GEO_WRITER_SYSTEM_PROMPT_A, 
            language_code
        )
        localized_prompt_b = get_localized_system_prompt(
            GEO_WRITER_SYSTEM_PROMPT_B, 
            language_code
        )
        
        # Run both writers in parallel
        with trace.span("writer_a_generation", kind=SpanKind.LLM) as span_a:
            task_a = self._run_writer_a(research_brief, target_question, localized_prompt_a)
        
        with trace.span("writer_b_generation", kind=SpanKind.LLM) as span_b:
            task_b = self._run_writer_b(research_brief, target_question, localized_prompt_b)
        
        draft_a, draft_b = await asyncio.gather(task_a, task_b)
        
        return draft_a, draft_b
    
    @trace.span("evaluation_with_feedback")
    async def _evaluation_loop(
        self,
        draft_a: str,
        draft_b: str,
        research_brief: dict,
        target_question: str,
        language_code: str,
        max_iterations: int = 3
    ) -> dict:
        """Run evaluation loop with detailed tracing."""
        
        iteration = 0
        current_draft_a = draft_a
        current_draft_b = draft_b
        
        while iteration < max_iterations:
            iteration += 1
            
            with trace.span(f"evaluation_iteration_{iteration}") as span:
                # Run evaluation
                evaluation = await self._evaluate_drafts(
                    current_draft_a,
                    current_draft_b,
                    research_brief,
                    target_question
                )
                
                span.set_attribute("draft_a_score", evaluation["draft_a"]["score"])
                span.set_attribute("draft_b_score", evaluation["draft_b"]["score"])
                span.set_attribute("passes_threshold", evaluation["passes_threshold"])
                
                if evaluation["passes_threshold"]:
                    # Generate GEO performance commentary
                    commentary = await self._generate_geo_commentary(
                        evaluation,
                        language_code
                    )
                    
                    selected = "A" if evaluation["draft_a"]["score"] >= evaluation["draft_b"]["score"] else "B"
                    selected_content = current_draft_a if selected == "A" else current_draft_b
                    
                    return {
                        "content": selected_content,
                        "selected": selected,
                        "score": max(evaluation["draft_a"]["score"], evaluation["draft_b"]["score"]),
                        "iterations": iteration,
                        "evaluation": evaluation,
                        "geo_commentary": commentary
                    }
                
                # Revision needed - trace feedback
                with trace.span("revision_feedback") as feedback_span:
                    feedback_span.set_attribute("revision_targets", evaluation["revision_needed"])
                    
                    # Apply revisions
                    if "A" in evaluation["revision_needed"]:
                        current_draft_a = await self._revise_draft(
                            current_draft_a,
                            evaluation["draft_a"]["feedback"],
                            language_code
                        )
                    if "B" in evaluation["revision_needed"]:
                        current_draft_b = await self._revise_draft(
                            current_draft_b,
                            evaluation["draft_b"]["feedback"],
                            language_code
                        )
        
        # Max iterations reached - select best available
        selected = "A" if evaluation["draft_a"]["score"] >= evaluation["draft_b"]["score"] else "B"
        commentary = await self._generate_geo_commentary(evaluation, language_code)
        
        return {
            "content": current_draft_a if selected == "A" else current_draft_b,
            "selected": selected,
            "score": max(evaluation["draft_a"]["score"], evaluation["draft_b"]["score"]),
            "iterations": iteration,
            "evaluation": evaluation,
            "geo_commentary": commentary
        }
```

### 3.4 Trace Visualization

The OpenAI Trace dashboard provides:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ TRACE: geo_content_generation                                               â”‚
â”‚ ID: 550e8400-e29b-41d4-a716-446655440000                                   â”‚
â”‚ Duration: 45.2s | Status: Success | Cost: $0.087                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚ â”œâ”€ language_detection (0.3s)                                               â”‚
â”‚ â”‚   â””â”€ Detected: zh-TW (Traditional Chinese) | Confidence: 0.95           â”‚
â”‚ â”‚                                                                           â”‚
â”‚ â”œâ”€ research_phase (12.4s)                                                  â”‚
â”‚ â”‚   â”œâ”€ harvest_web_content (8.2s)                                          â”‚
â”‚ â”‚   â”‚   â””â”€ Sources: 5 | Words harvested: 12,450                           â”‚
â”‚ â”‚   â”œâ”€ extract_statistics (2.1s)                                           â”‚
â”‚ â”‚   â”‚   â””â”€ Statistics found: 8                                             â”‚
â”‚ â”‚   â””â”€ collect_citations (2.1s)                                            â”‚
â”‚ â”‚       â””â”€ Expert quotes: 4 | Credible sources: 6                         â”‚
â”‚ â”‚                                                                           â”‚
â”‚ â”œâ”€ content_generation (18.5s)                                              â”‚
â”‚ â”‚   â”œâ”€ writer_a_generation [GPT-4.1-mini] (9.2s)                          â”‚
â”‚ â”‚   â”‚   â””â”€ Words: 523 | Tokens: 1,847                                     â”‚
â”‚ â”‚   â””â”€ writer_b_generation [Claude 3.5 Haiku] (9.3s)                      â”‚
â”‚ â”‚       â””â”€ Words: 498 | Tokens: 1,762                                     â”‚
â”‚ â”‚                                                                           â”‚
â”‚ â”œâ”€ evaluation_loop (14.0s)                                                 â”‚
â”‚ â”‚   â”œâ”€ evaluation_iteration_1 (7.2s)                                       â”‚
â”‚ â”‚   â”‚   â”œâ”€ Draft A Score: 72/100 âœ“                                        â”‚
â”‚ â”‚   â”‚   â”œâ”€ Draft B Score: 81/100 âœ“ â˜… Selected                             â”‚
â”‚ â”‚   â”‚   â””â”€ Passes Threshold: Yes                                          â”‚
â”‚ â”‚   â””â”€ generate_geo_commentary (6.8s)                                      â”‚
â”‚ â”‚       â””â”€ Commentary generated for user                                   â”‚
â”‚ â”‚                                                                           â”‚
â”‚ â””â”€ RESULT                                                                   â”‚
â”‚     â”œâ”€ Selected: Draft B (Claude 3.5 Haiku)                               â”‚
â”‚     â”œâ”€ Final Score: 81/100                                                 â”‚
â”‚     â”œâ”€ Language: Traditional Chinese (zh-TW)                               â”‚
â”‚     â””â”€ GEO Commentary: Included                                            â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.5 Trace Metadata Schema

```python
from pydantic import BaseModel
from datetime import datetime
from typing import Optional

class TraceMetadata(BaseModel):
    """Metadata captured in each trace."""
    
    # Request identification
    trace_id: str
    request_id: str
    client_name: str
    
    # Timing
    request_timestamp: datetime
    completion_timestamp: Optional[datetime] = None
    total_duration_ms: Optional[int] = None
    
    # Language
    input_language: str
    detected_dialect: Optional[str] = None
    
    # Research metrics
    sources_harvested: int = 0
    statistics_found: int = 0
    quotes_collected: int = 0
    
    # Generation metrics
    draft_a_tokens: int = 0
    draft_b_tokens: int = 0
    
    # Evaluation metrics
    evaluation_iterations: int = 0
    draft_a_final_score: float = 0
    draft_b_final_score: float = 0
    selected_draft: str = ""
    
    # Cost tracking
    total_input_tokens: int = 0
    total_output_tokens: int = 0
    estimated_cost_usd: float = 0
    
    # Status
    completion_status: str = "pending"
    error_message: Optional[str] = None
```

---

## 4. GEO Performance Commentary

### 4.1 Evaluator Commentary Feature

The Evaluator Agent generates a detailed commentary explaining why the selected output will achieve excellent GEO performance. This helps users understand and trust the optimization decisions.

### 4.2 Commentary Structure

```python
from pydantic import BaseModel
from typing import List

class GEOStrategyAnalysis(BaseModel):
    """Analysis of a single GEO strategy application."""
    strategy_name: str
    applied_count: int
    expected_visibility_boost: str
    specific_examples: List[str]
    effectiveness_rating: str  # "Excellent", "Good", "Adequate", "Needs Improvement"

class EEATAnalysis(BaseModel):
    """Analysis of E-E-A-T signals in content."""
    experience_signals: List[str]
    expertise_signals: List[str]
    authority_signals: List[str]
    trust_signals: List[str]
    overall_eeat_score: int  # 0-10

class GEOPerformanceCommentary(BaseModel):
    """Complete GEO performance commentary for user."""
    
    # Summary
    overall_assessment: str
    predicted_visibility_improvement: str
    confidence_level: str
    
    # Detailed Analysis
    strategy_analysis: List[GEOStrategyAnalysis]
    eeat_analysis: EEATAnalysis
    
    # Strengths
    key_strengths: List[str]
    
    # Comparison (why this draft was selected)
    selection_rationale: str
    comparative_advantages: List[str]
    
    # Structure Analysis
    opening_effectiveness: str
    structure_quality: str
    entity_mention_analysis: str
    
    # Recommendations for further improvement (optional)
    enhancement_suggestions: List[str]
```

### 4.3 Commentary Generation Implementation

```python
GEO_COMMENTARY_PROMPT = """
You are a GEO (Generative Engine Optimization) expert analyst. Your task is to
provide a detailed, educational commentary explaining why the selected content
will achieve excellent visibility in generative search engines.

## YOUR ANALYSIS MUST INCLUDE:

### 1. OVERALL ASSESSMENT
Provide a clear summary of the content's GEO performance potential.
Include a predicted visibility improvement percentage based on the strategies applied.

### 2. GEO STRATEGY ANALYSIS
For each strategy applied, explain:
- What was done (with specific examples from the content)
- Expected visibility impact (cite research: Statistics +25-40%, Quotations +27-40%, etc.)
- Effectiveness rating

### 3. E-E-A-T SIGNAL ANALYSIS
Identify specific signals for each dimension:
- **Experience:** Case studies, real examples, testimonials
- **Expertise:** Technical accuracy, domain terminology
- **Authoritativeness:** Citations, expert quotes, industry references
- **Trustworthiness:** Verified statistics, source attribution, transparency

### 4. KEY STRENGTHS
List the top 3-5 strengths that will drive GEO performance.

### 5. SELECTION RATIONALE
Explain why this draft was chosen over the alternative:
- Score comparison
- Specific advantages
- Strategy effectiveness differences

### 6. STRUCTURE EFFECTIVENESS
Analyze:
- Opening statement (critical for position-adjusted visibility)
- Heading hierarchy
- Entity mentions
- Information flow

### 7. ENHANCEMENT SUGGESTIONS (Optional)
If there are opportunities for further improvement, list 2-3 actionable suggestions.

## OUTPUT FORMAT
Provide the analysis in a clear, readable format that helps the user understand
exactly why this content will perform well in generative search engines.

Be specific with examples from the actual content. Reference the research-backed
visibility improvements for each strategy.
"""

class GEOCommentaryGenerator:
    """Generate detailed GEO performance commentary."""
    
    def __init__(self, model: str = "gpt-4.1"):
        self.model = model
    
    @trace.span("generate_geo_commentary")
    async def generate(
        self,
        selected_content: str,
        evaluation_results: dict,
        alternative_content: str,
        language_code: str
    ) -> GEOPerformanceCommentary:
        """Generate comprehensive GEO performance commentary."""
        
        from openai import AsyncOpenAI
        client = AsyncOpenAI()
        
        # Determine output language for commentary
        commentary_language_instruction = self._get_commentary_language(language_code)
        
        response = await client.chat.completions.create(
            model=self.model,
            messages=[
                {
                    "role": "system",
                    "content": GEO_COMMENTARY_PROMPT + "\n\n" + commentary_language_instruction
                },
                {
                    "role": "user",
                    "content": f"""
## SELECTED CONTENT (Draft {evaluation_results['selected']}):
{selected_content}

## ALTERNATIVE CONTENT (Draft {'B' if evaluation_results['selected'] == 'A' else 'A'}):
{alternative_content}

## EVALUATION SCORES:
- Selected Draft Score: {evaluation_results['selected_score']}/100
- Alternative Draft Score: {evaluation_results['alternative_score']}/100

## DETAILED EVALUATION:
{json.dumps(evaluation_results['detailed'], indent=2)}

Please provide a comprehensive GEO performance commentary explaining why the
selected content will achieve excellent visibility in generative search engines.
"""
                }
            ],
            response_format={"type": "json_object"},
            temperature=0.3
        )
        
        commentary_data = json.loads(response.choices[0].message.content)
        return GEOPerformanceCommentary(**commentary_data)
    
    def _get_commentary_language(self, language_code: str) -> str:
        """Get instruction for commentary output language."""
        
        if language_code.startswith("zh-TW"):
            return "è«‹ä½¿ç”¨ç¹é«”ä¸­æ–‡æ’°å¯«è©•è«–åˆ†æã€‚"
        elif language_code.startswith("zh-CN"):
            return "è¯·ä½¿ç”¨ç®€ä½“ä¸­æ–‡æ’°å†™è¯„è®ºåˆ†æã€‚"
        elif language_code.startswith("ar-"):
            return "ÙŠØ±Ø¬Ù‰ ÙƒØªØ§Ø¨Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„ ÙˆØ§Ù„ØªØ¹Ù„ÙŠÙ‚Ø§Øª Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©."
        else:
            return "Write the commentary in English."
```

### 4.4 Sample Commentary Output

```json
{
  "overall_assessment": "This content demonstrates excellent GEO optimization with a predicted visibility improvement of 32-38% in generative search engine responses. The combination of statistical evidence, expert quotations, and fluent writing creates highly citable content.",
  
  "predicted_visibility_improvement": "32-38%",
  "confidence_level": "High",
  
  "strategy_analysis": [
    {
      "strategy_name": "Statistics Addition",
      "applied_count": 5,
      "expected_visibility_boost": "+25-40%",
      "specific_examples": [
        "\"According to the Hong Kong Tourism Board, Ocean Park welcomed 7.6 million visitors in 2023\"",
        "\"The Grand Aquarium houses over 5,000 fish from 400+ species\"",
        "\"Visitor satisfaction ratings average 4.7 out of 5 stars\""
      ],
      "effectiveness_rating": "Excellent"
    },
    {
      "strategy_name": "Quotation Addition",
      "applied_count": 3,
      "expected_visibility_boost": "+27-40%",
      "specific_examples": [
        "\"Ocean Park offers an unmatched combination of marine education and thrilling entertainment,\" said Dr. Wong, Chief Conservation Officer",
        "\"The giant panda exhibit is a must-see for any visitor to Hong Kong,\" according to National Geographic"
      ],
      "effectiveness_rating": "Excellent"
    },
    {
      "strategy_name": "Citation Addition",
      "applied_count": 6,
      "expected_visibility_boost": "+24-30%",
      "specific_examples": [
        "Referenced: Hong Kong Tourism Board",
        "Referenced: Themed Entertainment Association",
        "Referenced: World Association of Zoos and Aquariums"
      ],
      "effectiveness_rating": "Excellent"
    },
    {
      "strategy_name": "Fluency Optimization",
      "applied_count": 1,
      "expected_visibility_boost": "+24-30%",
      "specific_examples": [
        "Flesch-Kincaid Grade Level: 8.2 (optimal range 8-10)",
        "Clear paragraph structure with logical flow",
        "No jargon or overly complex sentences"
      ],
      "effectiveness_rating": "Excellent"
    }
  ],
  
  "eeat_analysis": {
    "experience_signals": [
      "Specific details about attractions (Giant Panda Adventure, Grand Aquarium)",
      "Real visitor experience mentions",
      "Detailed descriptions of park areas"
    ],
    "expertise_signals": [
      "Accurate conservation terminology",
      "Correct species counts and park statistics",
      "Industry-specific knowledge demonstrated"
    ],
    "authority_signals": [
      "Hong Kong Tourism Board citation",
      "Expert quote from Chief Conservation Officer",
      "National Geographic reference"
    ],
    "trust_signals": [
      "All statistics include source attribution",
      "Verifiable visitor numbers",
      "Official organization references"
    ],
    "overall_eeat_score": 9
  },
  
  "key_strengths": [
    "Opening statement directly answers the query within the first 40 words, maximizing position-adjusted visibility",
    "Strong combination of Fluency + Statistics strategies (research shows +35.8% improvement)",
    "Expert quotations add credibility and increase citation likelihood by 27-40%",
    "6 credible external sources cited, exceeding the recommended 4-6 citations",
    "Entity (Ocean Park) mentioned 5 times naturally throughout the content"
  ],
  
  "selection_rationale": "Draft B was selected over Draft A due to superior E-E-A-T signal integration (9/10 vs 7/10) and more effective quotation placement. While both drafts applied similar GEO strategies, Draft B's quotations were positioned earlier in the content, benefiting from the exponential position weighting in visibility calculations.",
  
  "comparative_advantages": [
    "Draft B's opening statement is more direct and includes the entity name immediately",
    "Expert quotes in Draft B appear in paragraphs 1 and 2, vs paragraphs 3 and 4 in Draft A",
    "Draft B achieves better Flesch-Kincaid score (8.2 vs 9.8)",
    "Draft B includes one additional credible citation (6 vs 5)"
  ],
  
  "opening_effectiveness": "Excellent. The opening 47 words directly answer the query, include the client name (Ocean Park), state the primary value proposition (world-class marine theme park), and include a compelling statistic (7.6 million visitors). This front-loading of key information maximizes the position-adjusted word count metric.",
  
  "structure_quality": "The content follows optimal GEO structure with semantic H2 headings that mirror common query patterns, 2-3 sentence paragraphs with clear topic sentences, and a strong closing that reinforces the main message.",
  
  "entity_mention_analysis": "Ocean Park is mentioned 5 times throughout the 512-word article, achieving the recommended density of 3-5 mentions. Mentions are distributed across the opening, body, and closing sections.",
  
  "enhancement_suggestions": [
    "Consider adding one more statistic about conservation achievements to strengthen the expertise signal",
    "A brief comparison with similar attractions could enhance uniqueness factor"
  ]
}
```

### 4.5 User-Facing Commentary Display

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ğŸ¯ GEO PERFORMANCE ANALYSIS                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  OVERALL ASSESSMENT                                                         â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                         â”‚
â”‚  This content demonstrates excellent GEO optimization with a predicted      â”‚
â”‚  visibility improvement of 32-38% in generative search engine responses.   â”‚
â”‚                                                                             â”‚
â”‚  Confidence: HIGH | Selected: Draft B (Claude 3.5 Haiku) | Score: 81/100   â”‚
â”‚                                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  ğŸ“Š GEO STRATEGIES APPLIED                                                  â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                  â”‚
â”‚                                                                             â”‚
â”‚  âœ… Statistics Addition (5 found)           Expected boost: +25-40%        â”‚
â”‚     â€¢ "7.6 million visitors in 2023"                                       â”‚
â”‚     â€¢ "5,000 fish from 400+ species"                                       â”‚
â”‚     â€¢ "4.7 out of 5 star rating"                                           â”‚
â”‚                                                                             â”‚
â”‚  âœ… Quotation Addition (3 found)            Expected boost: +27-40%        â”‚
â”‚     â€¢ Dr. Wong, Chief Conservation Officer                                 â”‚
â”‚     â€¢ National Geographic reference                                         â”‚
â”‚                                                                             â”‚
â”‚  âœ… Citation Addition (6 found)             Expected boost: +24-30%        â”‚
â”‚     â€¢ Hong Kong Tourism Board                                               â”‚
â”‚     â€¢ Themed Entertainment Association                                      â”‚
â”‚     â€¢ World Association of Zoos and Aquariums                              â”‚
â”‚                                                                             â”‚
â”‚  âœ… Fluency Optimization                    Expected boost: +24-30%        â”‚
â”‚     â€¢ Flesch-Kincaid Grade: 8.2 (optimal)                                  â”‚
â”‚                                                                             â”‚
â”‚  Combined Strategy Bonus: Fluency + Statistics = +35.8% (research-backed)  â”‚
â”‚                                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  ğŸ† KEY STRENGTHS                                                           â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                           â”‚
â”‚  1. Opening directly answers query in first 40 words (max visibility)      â”‚
â”‚  2. Expert quotes positioned early for position-weighted advantage          â”‚
â”‚  3. 6 credible sources cited (exceeds recommended 4-6)                     â”‚
â”‚  4. Entity mentioned 5 times naturally                                      â”‚
â”‚  5. E-E-A-T score: 9/10                                                    â”‚
â”‚                                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  ğŸ†š WHY THIS DRAFT WAS SELECTED                                             â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                             â”‚
â”‚  Draft B outperformed Draft A (81 vs 72) due to:                           â”‚
â”‚  â€¢ More direct opening statement with immediate entity mention              â”‚
â”‚  â€¢ Expert quotes positioned in paragraphs 1-2 (vs 3-4 in Draft A)          â”‚
â”‚  â€¢ Better fluency score (8.2 vs 9.8 Flesch-Kincaid)                        â”‚
â”‚  â€¢ One additional credible citation                                         â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 5. Multi-Agent System Architecture

### 5.1 System Flow Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              USER INPUT                                      â”‚
â”‚    [Client Name] + [Target Question] + [Reference Sources]                  â”‚
â”‚                                                                              â”‚
â”‚    ğŸŒ Language Auto-Detection: EN | ç¹é«”ä¸­æ–‡ | ç®€ä½“ä¸­æ–‡ | Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         ğŸ“ OPENAI TRACE ENABLED                             â”‚
â”‚                    Full observability in OpenAI Dashboard                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         ğŸŒ LANGUAGE DETECTOR                                 â”‚
â”‚   Detect input language â†’ Set output language for all agents                â”‚
â”‚   Supported: EN, zh-TW, zh-CN, ar-MSA, ar-Gulf, ar-EG, ar-Levant, ar-Maghrebâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          ğŸ” RESEARCH AGENT                                   â”‚
â”‚   Model: GPT-4.1-mini | Framework: OpenAI Agent SDK                         â”‚
â”‚   Tools: PathwayWebHarvester, TavilySearch, DocumentParser                  â”‚
â”‚   Trace: research_phase span with source/statistics metrics                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                                     â–¼ [Handoff: research_brief]
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚   Research Brief +    â”‚
                         â”‚   Source Materials    â”‚
                         â”‚   + Detected Language â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚              [Parallel Execution]                 â”‚
           â–¼                                                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    âœï¸ WRITER AGENT A         â”‚         â”‚    âœï¸ WRITER AGENT B         â”‚
â”‚    Model: GPT-4.1-mini      â”‚         â”‚    Model: Claude 3.5 Haiku  â”‚
â”‚                             â”‚         â”‚                             â”‚
â”‚    Output Language:         â”‚         â”‚    Output Language:         â”‚
â”‚    [Auto-matched to input]  â”‚         â”‚    [Auto-matched to input]  â”‚
â”‚                             â”‚         â”‚                             â”‚
â”‚    Trace: writer_a span     â”‚         â”‚    Trace: writer_b span     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚                                       â”‚
               â–¼                                       â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ Draft A  â”‚                           â”‚ Draft B  â”‚
         â”‚ (åŒèªè¨€)  â”‚                           â”‚ (åŒèªè¨€)  â”‚
         â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                           â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
              â”‚                                      â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼ [Handoff: drafts]
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          âš–ï¸ EVALUATOR AGENT                                  â”‚
â”‚   Model: GPT-4.1 | Framework: OpenAI Agent SDK                              â”‚
â”‚   Trace: evaluation_loop span with iteration tracking                       â”‚
â”‚                                                                              â”‚
â”‚   Outputs:                                                                   â”‚
â”‚   â”œâ”€ Evaluation scores for both drafts                                      â”‚
â”‚   â”œâ”€ Selected draft with rationale                                          â”‚
â”‚   â””â”€ ğŸ“ GEO PERFORMANCE COMMENTARY (detailed explanation for user)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚   Pass Threshold?     â”‚
                         â”‚   (Score â‰¥ 70/100)    â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â–¼                                           â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚   PASS   â”‚                           â”‚      FAIL        â”‚
         â”‚          â”‚                           â”‚                  â”‚
         â”‚ Generate â”‚                           â”‚ [Handoff: feedback]
         â”‚ GEO      â”‚                           â”‚ Revision loop    â”‚
         â”‚ Comment  â”‚                           â”‚ (Max 3 cycles)   â”‚
         â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚                                          â”‚
              â–¼                                          â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        FINAL OUTPUT                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ â€¢ Optimized Content (in detected language)                             â”‚ â”‚
â”‚  â”‚ â€¢ Evaluation Scores                                                    â”‚ â”‚
â”‚  â”‚ â€¢ ğŸ“ GEO Performance Commentary (why this will excel)                  â”‚ â”‚
â”‚  â”‚ â€¢ Schema Markup                                                        â”‚ â”‚
â”‚  â”‚ â€¢ Trace URL for workflow inspection                                    â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 6. Development Environment Setup

### 6.1 uv Environment Configuration

```bash
# Install uv
curl -LsSf https://astral.sh/uv/install.sh | sh

# Create project
mkdir geo-content-platform && cd geo-content-platform

# Initialize with uv
uv init

# Create virtual environment
uv venv --python 3.11

# Activate
source .venv/bin/activate
```

### 6.2 Project Dependencies (pyproject.toml)

```toml
[project]
name = "geo-content-platform"
version = "3.2.0"
description = "Multi-Agent GEO Content Optimization Platform"
readme = "README.md"
requires-python = ">=3.11"
dependencies = [
    # OpenAI Agent SDK with tracing
    "openai-agents>=0.1.0",
    "openai>=1.50.0",
    
    # Anthropic SDK
    "anthropic>=0.39.0",
    
    # Pathway for web harvesting
    "pathway>=0.14.0",
    
    # Language detection
    "langdetect>=1.0.9",
    "arabic-reshaper>=3.0.0",
    "python-bidi>=0.4.2",
    
    # Web scraping
    "beautifulsoup4>=4.12.0",
    "httpx>=0.27.0",
    "playwright>=1.40.0",
    
    # Document processing
    "pypdf>=4.0.0",
    "python-docx>=1.1.0",
    "unstructured>=0.15.0",
    
    # Data handling
    "pydantic>=2.5.0",
    "pandas>=2.1.0",
    
    # API
    "fastapi>=0.109.0",
    "uvicorn>=0.27.0",
    
    # Utilities
    "python-dotenv>=1.0.0",
    "rich>=13.7.0",
    "tenacity>=8.2.0",
]

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"
```

### 6.3 Environment Variables

```bash
# .env
OPENAI_API_KEY=sk-...
OPENAI_MODEL_WRITER=gpt-4.1-mini
OPENAI_MODEL_EVALUATOR=gpt-4.1

ANTHROPIC_API_KEY=sk-ant-...
ANTHROPIC_MODEL_WRITER=claude-3-5-haiku-20241022

# Tracing
OPENAI_TRACING_ENABLED=true
OPENAI_TRACING_SERVICE_NAME=geo-content-platform
OPENAI_TRACING_ENVIRONMENT=production

# Web Search
TAVILY_API_KEY=...

# Application
MAX_ITERATIONS=3
QUALITY_THRESHOLD=70
```

---

## 7. API Response Schema

### 7.1 Complete Response Model

```python
from pydantic import BaseModel
from typing import List, Optional
from datetime import datetime

class ContentGenerationResponse(BaseModel):
    """Complete API response with all features."""
    
    # Request tracking
    job_id: str
    trace_id: str
    trace_url: str  # Link to OpenAI trace dashboard
    
    # Language
    detected_language: str
    language_code: str
    dialect: Optional[str] = None
    writing_direction: str  # "ltr" or "rtl"
    
    # Generated content
    content: str
    word_count: int
    
    # Evaluation
    selected_draft: str  # "A" or "B"
    evaluation_score: float
    evaluation_iterations: int
    
    # GEO Performance Commentary (NEW)
    geo_commentary: GEOPerformanceCommentary
    
    # Technical outputs
    schema_markup: dict
    geo_analysis: dict
    
    # Metadata
    generation_time_ms: int
    models_used: dict
    timestamp: datetime
```

### 7.2 Sample API Response

```json
{
  "job_id": "job_abc123",
  "trace_id": "550e8400-e29b-41d4-a716-446655440000",
  "trace_url": "https://platform.openai.com/traces/550e8400-e29b-41d4-a716-446655440000",
  
  "detected_language": "Traditional Chinese",
  "language_code": "zh-TW",
  "dialect": "Taiwan",
  "writing_direction": "ltr",
  
  "content": "é¦™æ¸¯æµ·æ´‹å…¬åœ’æ˜¯äºæ´²é ‚ç´šçš„æµ·æ´‹ä¸»é¡Œæ¨‚åœ’...",
  "word_count": 523,
  
  "selected_draft": "B",
  "evaluation_score": 81.5,
  "evaluation_iterations": 1,
  
  "geo_commentary": {
    "overall_assessment": "æ­¤å…§å®¹å±•ç¾å‡ºå„ªç§€çš„GEOå„ªåŒ–ï¼Œé è¨ˆåœ¨ç”Ÿæˆå¼æœå°‹å¼•æ“ä¸­å¯æå‡32-38%çš„èƒ½è¦‹åº¦...",
    "predicted_visibility_improvement": "32-38%",
    "confidence_level": "é«˜",
    "strategy_analysis": [...],
    "eeat_analysis": {...},
    "key_strengths": [...],
    "selection_rationale": "Bç¨¿å› å…¶æ›´å„ªç§€çš„E-E-A-Tä¿¡è™Ÿæ•´åˆè€Œè¢«é¸ä¸­...",
    "comparative_advantages": [...],
    "enhancement_suggestions": [...]
  },
  
  "schema_markup": {
    "@context": "https://schema.org",
    "@type": "TouristAttraction",
    "name": "é¦™æ¸¯æµ·æ´‹å…¬åœ’",
    ...
  },
  
  "geo_analysis": {
    "statistics_count": 5,
    "citations_count": 6,
    "quotations_count": 3,
    "fluency_score": 8.2,
    "eeat_score": 9
  },
  
  "generation_time_ms": 45200,
  "models_used": {
    "research": "gpt-4.1-mini",
    "writer_a": "gpt-4.1-mini",
    "writer_b": "claude-3-5-haiku-20241022",
    "evaluator": "gpt-4.1"
  },
  "timestamp": "2025-12-01T14:32:15Z"
}
```

---

## 8. Implementation Checklist

### Phase 1: Environment & Foundation (Week 1)
- [ ] Initialize uv project with dependencies
- [ ] Configure environment variables including tracing
- [ ] Set up OpenAI Agent SDK with trace configuration
- [ ] Implement language detection tool
- [ ] Create Pydantic models for all data structures

### Phase 2: Pathway & Research (Week 2-3)
- [ ] Implement PathwayWebHarvester with tracing
- [ ] Create search pipeline with Tavily
- [ ] Build research agent with full trace spans
- [ ] Test multilingual research capability

### Phase 3: Writer Agents (Week 4)
- [ ] Implement Writer Agent A (GPT-4.1-mini) with language support
- [ ] Implement Writer Agent B (Claude 3.5 Haiku) with language support
- [ ] Add Arabic RTL formatting support
- [ ] Test all supported languages

### Phase 4: Evaluator & Commentary (Week 5-6)
- [ ] Implement Evaluator Agent with scoring
- [ ] Build GEO Commentary Generator
- [ ] Implement feedback loop with trace spans
- [ ] Create multilingual commentary support

### Phase 5: API & Integration (Week 7-8)
- [ ] Build FastAPI application with full response schema
- [ ] Implement trace URL generation
- [ ] Add export functionality
- [ ] Create API documentation

### Phase 6: Testing & Launch (Week 9-10)
- [ ] Test all language variants
- [ ] Verify trace integration in OpenAI dashboard
- [ ] Performance optimization
- [ ] Beta testing with pilot clients

---

## 9. Appendices

### A. Supported Languages Reference

| Language | Code | Detection Markers | RTL | Models Tested |
|----------|------|-------------------|-----|---------------|
| English | en | Latin script | No | âœ… GPT-4.1-mini, Claude 3.5 Haiku |
| Traditional Chinese | zh-TW | ç¹é«”å­— markers | No | âœ… GPT-4.1-mini, Claude 3.5 Haiku |
| Simplified Chinese | zh-CN | ç®€ä½“å­— markers | No | âœ… GPT-4.1-mini, Claude 3.5 Haiku |
| Arabic (MSA) | ar-MSA | Arabic script, formal | Yes | âœ… GPT-4.1-mini, Claude 3.5 Haiku |
| Arabic (Gulf) | ar-Gulf | Gulf dialect markers | Yes | âœ… GPT-4.1-mini, Claude 3.5 Haiku |
| Arabic (Egyptian) | ar-EG | Egyptian markers | Yes | âœ… GPT-4.1-mini, Claude 3.5 Haiku |
| Arabic (Levantine) | ar-Levant | Levantine markers | Yes | âœ… GPT-4.1-mini, Claude 3.5 Haiku |
| Arabic (Maghrebi) | ar-Maghreb | Maghrebi markers | Yes | âœ… GPT-4.1-mini, Claude 3.5 Haiku |

### B. Document History

| Version | Date | Changes |
|---------|------|---------|
| 3.0 | Dec 1, 2025 | Deep GEO research integration |
| 3.1 | Dec 1, 2025 | OpenAI Agent SDK, GPT-4.1-mini, Pathway, uv |
| 3.2 | Dec 1, 2025 | Language detection, OpenAI Trace, GEO Commentary |

---

*Document Classification: Confidential*  
*Â© 2025 Tocanan.ai. All rights reserved.*
